{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f00ec3",
   "metadata": {},
   "source": [
    "# SGLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc190df",
   "metadata": {},
   "source": [
    "## 1. Stochastic Gradient Langevin Dynamics for Stochastic Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607287a5",
   "metadata": {},
   "source": [
    "### **A. Stochastic Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf4168",
   "metadata": {},
   "source": [
    "* 실제 Data Distribution은 구할 수 없음 (사실상)\n",
    "* 개별 손실 함수를 최적화할 필요 있음 -> Convex / High Dimension\n",
    "* 최적화 중 멈추거나 발산할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa691a9",
   "metadata": {},
   "source": [
    "### **B. Stochastic Approximation Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938a86e",
   "metadata": {},
   "source": [
    "* SGD : 기댓값은 최적점\n",
    "* Adam-type Optimizer : 2020년대까지 핵심 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeddb94",
   "metadata": {},
   "source": [
    "### **C. SGLD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b73db",
   "metadata": {},
   "source": [
    "$$\\theta_{n+1} = \\theta_n - \\lambda H(\\theta_n, X_n) + \\sqrt{2\\lambda \\beta^{-1}} \\zeta_n, ~ \\zeta_n \\sim N(0, 1)$$\n",
    "\n",
    "* SGD에 임의로 가우시안 노이즈를 넣음\n",
    "* Distribution 추정의 Sampling Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3a109",
   "metadata": {},
   "source": [
    "`-` Langevin SGE\n",
    "\n",
    "* 샘플링, 노이즈화 정규 분포로 근사시킴\n",
    "\n",
    "`-` Gibbs Measure는 Non-Convex 문제에서 최적해 근처에서의 높은 확률\n",
    "\n",
    "> 샘플링 문제로 최적화를 치환했을 때, 최적해 근처에 샘플이 많이 모임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08aa54",
   "metadata": {},
   "source": [
    "`-` Dissipativity Condition\n",
    "\n",
    "* 어떤 공간이 상으로부터 멀어졌을 때, 그래디언트는 가까워지도록 만듦\n",
    "* 모든 stationary point를 ball안에 한정할 수 있음 -> general한 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b9abb9",
   "metadata": {},
   "source": [
    "`-` Poincare Inequality\n",
    "\n",
    "* 마코프 체인이 얼마나 빠르게 수렴하느냐를 결정\n",
    "* log subolev inequality : 암튼 이걸 씀 -> n이 커질수록 exponential하게 정확도? 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0def1",
   "metadata": {},
   "source": [
    "### **D. Recent Research Directions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9f09b",
   "metadata": {},
   "source": [
    "1. **Best Convergence Rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a278f",
   "metadata": {},
   "source": [
    "2. **Global lipschitz Continuity**\n",
    "\n",
    "* MLP만 해도 Global Lipschitz Continuity 불만족 -> local로 변경\n",
    "* 네?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e88c7",
   "metadata": {},
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f42584",
   "metadata": {},
   "source": [
    "4. **Beyond Euler-Maruyama Discretization**\n",
    "\n",
    "* adaptive -> polynomial approx : unbias gibbs measuer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaada47",
   "metadata": {},
   "source": [
    "5. **Beyond Dissipativity Condition**\n",
    "\n",
    "* 몰루?\n",
    "* exponential dependency를 없애는 걸 중점 -> Convexity at infinity / Semi-Convexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b31cd",
   "metadata": {},
   "source": [
    "## 2. Dual Cone Gradient Descent for Multi-Objective Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea44d8",
   "metadata": {},
   "source": [
    "### A. DCGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c4b78",
   "metadata": {},
   "source": [
    "* 요즘 AI는 여러 태스크에 적합하며, 하나의 파라미터로 여러 개의 optimization을 수행해야 하는 일이 생김\n",
    "* weighted total loss를 만들어서 최적화?\n",
    "> 1. gradient conflicts 발생\n",
    "> 2. 특정 loss에 집중되어 학습이 고르게 이뤄지지 않음\n",
    "> 3. Pareto 최적 없음\n",
    "> 4. 가중치에 민감하게 결과가 바뀜\n",
    ">\n",
    "> 새로운 optimization process가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ba73e",
   "metadata": {},
   "source": [
    "### B. Dual Cone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac91e93",
   "metadata": {},
   "source": [
    "* 원뿔에 대하여 경사로에 접하는 90도가 넘지 않는 두 개의 콘\n",
    "\n",
    "\n",
    "`-` `m = 2`인 경우 (두 개의 오브젝트)\n",
    "\n",
    "* dual cone의 gradient 방향이 non-negative하므로 한번에 둘 다 줄일 수 있음... ㅇㅅㅇ\n",
    "* 두 개의 그래디언트의 Span의 직교여공간을 잡았을 때, 듀얼콘 내부와 직교하는 벡터공간 있음 -> 차원 축소도 가능\n",
    "* pareto stationary point의 convergency를 보장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42a8dd",
   "metadata": {},
   "source": [
    "`-` `m > 2`인 general한 경우\n",
    "\n",
    "* 아무튼 잘 수렴함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47158ad9",
   "metadata": {},
   "source": [
    "> 그냥 파라미터를 늘리면 안되나?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee927827",
   "metadata": {},
   "source": [
    "### C. Problem Solving\n",
    "\n",
    "`-` Partial Differential Equations PDEs\n",
    "\n",
    "* 딥러닝으로 근사적 접근 어쩌구\n",
    "\n",
    "`-` PINNs\n",
    "\n",
    "* 엄\n",
    "\n",
    "`-` Machine Unlearning\n",
    "\n",
    "* AI 모델에서 특정 대상의 데이터를 제거해야 하는 상황... 어케함 -> 해당 데이터를 지운 다음에 retraining... 말도 안됨\n",
    "* 데이터를 보지 않고 학습한 것처럼 만드는 방법론\n",
    "* 기존 데이터 제거 loss + 성능 유지 loss. 두 개의 loss를 weighted sum하여 최적화 -> Conflict한 경우 total gradient가 dual cone 안에 들어있지 않은 경우 모델 퍼포먼스 하락\n",
    "* 규제 발생 시 특정 unlearning accuracy를 달성해야 함 -> 하이퍼 파라미터 조정으로 수행... 하지만 간접적으로 관련있기 때문에 어떻게 해야 할지 모호함\n",
    "* Evaluation Metric : Unlearning Acc / Real Acc 정도에 따른 스코어 비교 불가\n",
    "\n",
    "> Multi-Objective pareto front를 찾는 문제와 동치\n",
    ">\n",
    "> Dual Cone 내부에서도 각도에 따라 뭐 다름. pivoting parameter 존재 -> Algorithm Control 가능\n",
    ">\n",
    "> Diversity / Optimality. 다른 모델들에 비해 파레토 최적 측면에서 성능 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ca0d5",
   "metadata": {},
   "source": [
    "* 알고리즘이 아닌 프레임워크임 -> 여러 응용이 가능, Varient를 다양하게 만들 수 있음, 아무튼 잘 써질 수 있음\n",
    "* Stochastic Method를 바로 적용하기에는 구조적 측면에서 복잡한 과정이 필요할 수 있음 ㅇㅇ 바로 적용 안됨"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
